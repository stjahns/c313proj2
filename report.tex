\documentclass[twocolumn]{article}
\usepackage[letterpaper, left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{graphicx}
%\usepackage{estopdf}
\usepackage{verbatim}
\usepackage{listings}
\begin{document}

\lstset{
language=C,                             % Code langugage
basicstyle=\ttfamily,                   % Code font, Examples: \footnotesize, \ttfamily
numbers=left,                           % Line nums position
numberstyle=\tiny,                      % Line-numbers fonts
stepnumber=1,                           % Step between two line-numbers
numbersep=5pt,                          % How far are line-numbers from code
frame=none,                             % A frame around the code
tabsize=2,                              % Default tab size
captionpos=b,                           % Caption-position = bottom
breaklines=true,                        % Automatic line breaking?
breakatwhitespace=false,                % Automatic breaks only at whitespace?
showspaces=false,                       % Dont make spaces visible
showtabs=false,                         % Dont make tabls visible
columns=flexible                        % Column format
}

\title{CMPUT 313 Assignment 2}
\date{Tuesday, March 13}
\author{Stephen Jahns and Marek Kundera}

\maketitle

\section*{Introduction}

	Choosing an appropriate backoff strategy for the Slotted ALOHA MAC layer
	protocol depends on a series of factors. In this report, we have
	simulated the Probabilistic Backoff ($P$), Interval-Based Backoff ($I$),
	and Truncated Binary Exponential Backoff ($B$) strategies. In addition,
	we have simulated the Time Division Multiplexing ($T$) protocol for
	additional comparison. Our simulation was based on several assumptions
	found in the problem specification and on a terse description of each
	protocol:

$T$: a station $i$ only transmits at slot number $mN + i$, $m$ = 0, 1, 2, ...
$N$, where $m$ is the cycle number, and $N$ is the number of stations

$P$: a station will try to transmit immediately on generation, or retransmit
with $1/N$ probability at each subsequent slot

$I$: a station will try to transmit immediately on generation, or retransmit at
a slot 1 to $N$ slots later, chosen randomly

$B$: a station will try to transmit immediately on generation, or retransmit at
a slot 1 to 2 slots later, then 1 to 4 slots later, or eventually 1 to $2^i$
slots later, chosen randomly until the frame successfully transmits

	To set some groundwork, we will begin by outlining our expectations with
	a preliminary analysis. Next we will briefly explain the main
	functionality and design of our \verb|psim| simulator. Then we will reveal the
	simulation results with the help of some tables and graphs, paired with
	the parameters we used to generate the media. Finally, we will examine
	each protocol's performance by analyzing their average throughputs and
	the overall average per-frame slot time delays of the successfully
	transmitted frames. In addition, we will examine the fairness of each
	protocol by observing the number of undelivered frames under each
	protocol at the individual stations.

\subsection*{Time Division Multiplexing} Here we expect that as the probability
of frame generation, $p$, increases, the average frame delay should increase. This is
because in any given cycle of $N$ slots, the probability of a frame being
generated at that slot increases. Therefore as $p$ increases, up to $N$ frames
might be generated in a cycle.  On the other hand, the mean throughput should
increase in direct proportion to $p$. As $p$ increases, it is more likely frames
will be available for transmission in a given cycle. In other words, it is more
likely a station will not waste its designated slot time. Furthermore, since
each station has a designated slot only it can transmit on, it is not possible
for collisions to occur between the stations. 
A potential serious weakness of TDM is that if the load is not equally balanced 
between the stations on the bus, unnecessary delays may occur, especially if only
a single station has a very large number of frames queued for a period of many slots.
The busy station will experience delays of $N$ slots between each frame transmitted,
while all other slots are left unused, leaving the overall hub throughput very low and
the delay unnecessarily high.

\subsection*{Probabilistic Backoff} Notice that for a probability of successful
transmission of $1/N$, we need $N$ stations to each have a frame queued for
transmission, in order for one to \emph{likely} transmit. We can build on this
observation and hypothesize that at some $p$, every station will be generating
frames faster than it can transmit them. And therefore, the throughput will
level off in concert with the probability that \emph{exactly one} station
transmits, i.e. let event $ExactlyOneTx$ represent the case where exactly one
station is transmitting. Thus, when $N$=20 stations, $Prob(ExactlyOneTx)$ =
$C(20,1)\times(1/20)\times(19/20)^{19}$ = 0.377. For 20 stations, it is likely
then that when $p=0.377/20=0.019$, we can expect the throughput to begin
leveling off and for the average frame delay to start increasing. This is
because as $p$ increases, frames are more likely to generate, while the
throughput remains the same. And so, the queue can only get larger thus each
frame must wait longer before moving to the front of the queue for transmission.

\subsection*{Interval-Based Backoff} In a similar fashion to the probabilistic
backoff, as $p$ is increased, we predict that some critical point will be reached
where the rate of generation will be higher than the rate of transmission, and so the
queues at each station will grow, increasing the average frame delay. Additionally,
the throughput will level out as the probability of a collision stabilizes along with
the rate of successful transmission. Consider an analogy of $N$=20 buckets. At each time
slot, each station has $p$ chance of adding a 'ball to one bucket'. Therefore, in the
long run, the frames generated per slot is $N\times p$ while the rate of transmission
can be 1 at best, but realistically much lower (let's say $Z$). It is easy to see that
as $p$ increases, eventually the rate of generation will be greater than the rate of
transmission (or throughput), i.e. $N\times p \geq Z$. $Z$ can be said to be equal to
the probability that a bucket has exactly one ball. This isn't the same probability as
above, and it won't be calculated as it would involve higher level probabilistic math.
At this point however, the throughput will will level out and the average frame delay will increase
as $p$ increases.

\subsection*{Truncated Binary Exponential Backoff}

Truncated binary exponential backoff is more or less a fancy version of interval backoff 
where instead of a fixed interval size of $N$ slots to randomly backoff for, the interval
starts at 4 slots and doubles at every collision until 1024. Due to this property, if a
single station has at least 9 consecutive transmission attempts with collision, 
the interval before the next transmission attempt could be as long as 1024 slots. During low
loads on the bus, we should expect small delays as immediate transmission of a frame upon 
generation (if the transmission queue was previously empty) or after a successful transmission
is allowed. During progressively higher loads, the relative performance between TBEB and IB and PB in
in terms of hub throughput and average delivery delay may be difficult to predict. 

\section*{Methods}

The \verb|psim| simulator was implemented in C++. It requires several parameters
at the command line:

\begin{center}\verb|psim Protocol N p R T seed1 seed2 ... seedT|\end{center}

 \verb|Protocol| can taken on a value of \verb|T|, \verb|P|, \verb|I|, or \verb|B|, depending on
what protocol is being simulated. The parameter \verb|N| represents the number of
stations that will be transmitting under the protocol. \verb|p| represents the
probability that a frame will be generated at each station. \verb|R| represents the
number of slots that the experiment will run, and is therefore the time-measure
for the experiment. And \verb|T| represents the number of trials the simulation will
run, while the following \verb|seed1...seedT| inputs are used to reseed the
randomization functions for each trial. 

For the purpose of this simulation, the
values \verb|N=20|, \verb|R=50000|, and \verb|T=5| will be fixed. In other words, we will
simulate 5 trials where 20 stations transmit over a time period of 50,000 slots.
The observations shown later are based on 5 trials that were seeded with values
1, 2, 3, 4, 5, respectively.

\verb|psim| functions by simulating \verb|T| independent trials of hub of
\verb|N| stations running for \verb|R| time slots, using the random number
generator seeds separately specified for each trial. At the beginning of each
timeslot, each station generates a new frame on its transmission queue with
probability \verb|p|. Then, the delay value in time slots is incremented for
each frame on each stations transmission queue.  Then, the simulator determines
which and how many stations will attempt transmission in that timeslot,
according to the MAC protocol specified in \verb|Protocol|. If there is only one
station attempting transmission, the transmission is deemed successful and the
frame is removed from that station's queue. If there are more than one
transmissions, a \verb|tx_collide(slot)| method is executed on each station that
partly implements the station's backoff protocol as specified in
\verb|Protocol|.

The simulator outputs the parameters (minus the seeds) on the first line. After
running all trials, it calculates and prints 95\% confidence intervals for the
overall average throughput in frames delivered per time slot, and delay in slots
for each frame successfully delivered, on lines 2 and 3 respectively. Delay was 
calculated from the time of frame generation to the time of successful delivery in slots,
in a matter that the minimum delay is 1 if the frame is generated in the same slot that it is
delivered in. Confidence
intervals were calculated using appropriate t-statistics for the number of
trials from a file labelled \verb|tvalues.dat|. Per-station statistics were output
on the remaining lines, where each line started with \verb|nN|, the id of the station,
followed by confidence intervals for throughput and delay per frame delivered, and finally
the ratio of undelivered frames to total frames generated by that station for each trial 
separately, all on the same line.

Experiments were automated using the BASH script \verb|make_plot.sh| 
to run the simulator for each protocol over ranges of \verb|p| values ranging
from 0.00 up to 0.04. The scripts parsed data from the output into appropriately
formatted data files that were sent to GNUPLOT for plotting.

\section*{Results}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/delay_big.eps}
    \caption{\footnotesize  Average delay per frame under each protocol for
    $p$:(0,0.04; @0.005 increments). Used to illustrate what happens as $p$
    nears 0.04.} \label{fig:delay_big}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/throughput_big.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0,0.04; @0.005 increments). Used to illustrate what happens as $p$
    nears 0.04.} \label{fig:throughput_big}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/small_delay.eps}
    \caption{\footnotesize Average delay per frame under each protocol for
    $p$:(0,0.015; @0.001 increments). Used to illustrate what happens as $p$
    nears 0.} \label{fig:delay_small}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/small_throughput.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0,0.015; @0.001 increments). Used to illustrate what happens as $p$
    nears 0.} \label{fig:throughput_small}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/ib_diverge_delay.eps}
    \caption{\footnotesize Average delay per frame under each protocol for
    $p$:(0,0.02; @0.001 increments). Used to illustrate where protocols begin to
    diverge significantly. Especially, protocol $I$ at $p$=0.015.}
    \label{fig:delay_ib}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/ib_diverge_throughput.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0,0.02; @0.001 increments). Used to illustrate where protocols
    begin to diverge significantly. Especially, protocol $I$ at $p$=0.016.}
    \label{fig:throughput_ib}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/tpbi_delay.eps}
    \caption{\footnotesize Average delay per frame under each protocol for
    $p$:(0.01,0.021; @0.001 increments). Used to illustrate the points where the
    protocols intersect.} \label{fig:delay_diverging}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/tpbi_throughput.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0.01,0.021; @0.001 increments). Used to illustrate the points where
    the throughput for protocols $I$ and $P$ begins to level off.}
    \label{fig:throughput_diverging}
\end{figure}


For ranges of frame generation probabilities per station per slot ranging
from 0.0 to 0.04, plots of average delay in slots per frame successfully delivered and
of throughput in number of frames per timeslot were obtained. 

In Figure~\ref{fig:delay_big}, we see that over larger values of $p$ ranging up to
0.04, there is a clear separation in delay levels for each protocol. Interval backoff
produces the largest delays, followed by probabilistic backoff. Truncated binary exponential
backoff produces the least delays of the Slotted ALOHA MAC protocols. Time division multiplexing,
however, provides delivery delays at $p=0.04$ that are a tiny fraction of the delays of the 
ALOHA protocols. Similar results exist for throughput at higher loads ($p$ approaching 0.04) as 
seen in Figure~\ref{fig:throughput_big}. TBEB provides the highest throughput at high load,
followed by IB and PB. TDM provides a higher throughput at high load than the ALOHA protocols,
but by a much smaller margin (~10\% higher than TBEB) than exhibited by the difference in
delays.

At smaller loads (approx. $p<0.013$), the frame delivery delays for TDM become
larger than that of the ALOHA protocols (Figure~\ref{fig:delay_small}). The relative delays 
between the different ALOHA protocols also changes. For $p<0.012$, TBEB has the smallest delay,
but the delay increases strongly above that value. Interval backoff has the smallest delays
for 
$p \in (0.012, 0.016)$, after which the delay for IB jumps up sharply (Figure~\ref{fig:delay_ib}).
For $p > 0.016$, TDM has less delay than any of the ALOHA protocols, and PB has the smallest 
delay of the ALOHA protocols for $p \in (0.016, 0.02)$, after which the delay jumps to above
that of TBEB (Figure~\ref{fig:delay_diverging}). TBEB has the least delay of the ALOHA protocols
for $p > 0.02$.

All protocols produce very similar throughputs at low load for $p \in (0, 0.016)$
(see Figures ~\ref{fig:throughput_small} and ~\ref{fig:throughput_ib}), where
all throughputs appear to increase linearly with frame generation probability. 
Above $p=0.016$, IB throughput drops fairly quickly by about 20\% and flattens to a throughput
of about 25\% for all higher loads. Above $p=0.02$, PB throughput drops a little and flattens
to about 40\% for all higher loads. 

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/fullrange_delay5000.eps}
    \caption{Average delay per frame delivered on hub for full range of per
    slot, per station frame generation probability, tested for each MAC
    protocol  $R=5000$ slots, $T = 5$ trials.}
    \label{fig:fullrange_delay}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/fullrange_throughput5000.eps}
    \caption{Average throughput on hub for full range of per
    slot, per station frame generation probability, tested for each MAC
    protocol  $R=5000$ slots, $T = 5$ trials } 
    \label{fig:fullrange_throughput}
\end{figure}

\begin{table*}
    \centering 
%B 20 0.040000 50000 5 1 2 3 4 5
    \label{fig:fairness_pb}
    \begin{tabular}{l|c|c|c|c|c}
           & 1 & 2 & 3 & 4 & 5 \\
        \hline
        n1 & 0.508249 & 0.581281 & 0.539540  & 0.536810 & 0.536203 \\
        n2 & 0.519899 & 0.544526 & 0.561975  & 0.563332 & 0.536524 \\
        n3 & 0.481934 & 0.525169 & 0.486970  & 0.501256 & 0.544828 \\
        n4 & 0.545960 & 0.516467 & 0.479901  & 0.471414 & 0.493199 \\
        n5 & 0.566901 & 0.565152 & 0.511707  & 0.531282 & 0.539249 \\
        n6 & 0.535802 & 0.483191 & 0.508449  & 0.525551 & 0.479410 \\
        n7 & 0.545680 & 0.511827 & 0.541955  & 0.522461 & 0.505500 \\
        n8 & 0.533605 & 0.493834 & 0.534942  & 0.541357 & 0.506216 \\
        n9 & 0.530633 & 0.490852 & 0.550930  & 0.542089 & 0.502367 \\
       n10 & 0.559280 & 0.528793 & 0.560729  & 0.510886 & 0.522739 \\
       n11 & 0.518182 & 0.546937 & 0.552566  & 0.542323 & 0.528358 \\
       n12 & 0.518127 & 0.529263 & 0.535873  & 0.511548 & 0.521608 \\
       n13 & 0.472489 & 0.473892 & 0.547284  & 0.516274 & 0.522795 \\
       n14 & 0.499205 & 0.546417 & 0.497184  & 0.520791 & 0.538313 \\
       n15 & 0.545084 & 0.524158 & 0.527061  & 0.527906 & 0.573762 \\
       n16 & 0.503090 & 0.526585 & 0.511013  & 0.571001 & 0.580835 \\
       n17 & 0.519297 & 0.563939 & 0.516014  & 0.499746 & 0.511922 \\
       n18 & 0.508870 & 0.549527 & 0.542843  & 0.530334 & 0.513667 \\
       n19 & 0.545858 & 0.515464 & 0.560582  & 0.538499 & 0.518900 \\
       n20 & 0.495988 & 0.556727 & 0.498999  & 0.507109 & 0.526804
    \end{tabular}
%B 20 0.040000 50000 5 1 2 3 4 5
%0.696424 0.691729 0.701119
%4558.648255 4053.037562 5064.258947
    \caption{ Ratios of undelivered to total generated frames, per station, per trial using
       probabilistic backoff, $R=50000$ slots, $T = 5$ trials.
    Each column corresponds to a single trial, each row corresponds to a single station. }

\end{table*}

\begin{table*}
    \centering 
%B 20 0.040000 50000 5 1 2 3 4 5
    \label{fig:fairness_tbeb}
    \begin{tabular}{l|c|c|c|c|c}
           & 1 & 2 & 3 & 4 & 5 \\
        \hline
n1 & 0.077351 & 0.118118 & 0.425962 & 0.002500 & 0.052495 \\
n2 & 0.125247 & 0.062253 & 0.008973 & 0.386563 & 0.084267 \\
n3 & 0.061347 & 0.106634 & 0.146091 & 0.035376 & 0.079079 \\
n4 & 0.053150 & 0.073552 & 0.000000 & 0.316767 & 0.063099 \\
n5 & 0.115442 & 0.031403 & 0.084800 & 0.093294 & 0.018945 \\
n6 & 0.290680 & 0.310675 & 0.084221 & 0.040675 & 0.016035 \\
n7 & 0.285861 & 0.006979 & 0.057115 & 0.171313 & 0.364198 \\
n8 & 0.143426 & 0.054381 & 0.311475 & 0.043000 & 0.161356 \\
n9 & 0.016907 & 0.008755 & 0.156189 & 0.109576 & 0.201082 \\
n10 & 0.043048 & 0.133580 & 0.099445 & 0.224008 & 0.052000 \\
n11 & 0.090303 & 0.126420 & 0.418695 & 0.242541 & 0.003605 \\
n12 & 0.080145 & 0.000000 & 0.000000 & 0.339708 & 0.086697 \\
n13 & 0.185393 & 0.203203 & 0.003885 & 0.103681 & 0.031915 \\
n14 & 0.049010 & 0.190793 & 0.000000 & 0.144299 & 0.212091 \\
n15 & 0.240223 & 0.082819 & 0.314556 & 0.121367 & 0.091960 \\
n16 & 0.150581 & 0.078744 & 0.427317 & 0.024150 & 0.287167 \\
n17 & 0.016312 & 0.204412 & 0.003458 & 0.018482 & 0.377398 \\
n18 & 0.119456 & 0.179462 & 0.059233 & 0.029340 & 0.068982 \\
n19 & 0.135551 & 0.203085 & 0.072709 & 0.002467 & 0.083416 \\
n20 & 0.118554 & 0.331832 & 0.097561 & 0.129732 & 0.238192 
    \end{tabular}
%B 20 0.040000 50000 5 1 2 3 4 5
%0.696424 0.691729 0.701119
%4558.648255 4053.037562 5064.258947
    \caption{ Ratios of undelivered to total generated frames, per station, per trial using
        truncated binary exponential backoff, $R=50000$ slots, $T = 5$ trials.  
        Each column corresponds to a single trial, each row corresponds to a single station. }

\end{table*}

For the range of $p$ values that could be tested using \verb|R=50000| (higher
$p$ values resulted in at least polynomially higher simulation run times as the frame queues
became heavier loaded), we did not see a point where TBEB throughput levels off. Running
the simulator under the same conditions as before but with \verb|R=1000| and \verb|p| ranging
from 0 to 1, TBEB throughput appears to increase steadily until about 78\% at about $p = 0.5$,
and the same plot for \verb|R=5000| shows TBEB throughput leveling off at about 93\% 
(Figure~\ref{fig:fullrange_delay}). At \verb|R=5000|, IB and PB delays appear to level off at the
same values as for \verb|R=50000|.

In Figure~\ref{fig:fullrange_delay}, we also see that with sufficiently high load, TBEB yields
a lower average delay than T

In order to determine the relative fairness of each protocol with respect to individual stations
competing for transmissions on the hub, we measured per trial, per station ratios of 
undelivered frames to total frames generated at that station. For this metric, if the ratio
is 0 at the end of the trial, all frames were successfully delivered, and if the ratio is 1, 0
frames were successfully delivered. Simulations were run for
each of the protocols, and results for interval backoff and truncated binary exponential
backoff protocols are listed in Tables 1 and 2, respectively. Similar results for interval
backoff were observed as for probabilistic backoff. In Table 1, for PB we see that the
ratios for each station never stray below 0.45 or above 0.6 within a trial. In Table 2,
within a single trial, the ratios for each station range from 0 (all generated frames 
successfully delivered) to 0.43 (nearly half of all frames unsuccessfully delivered, left
in queue at end of trial).



\section*{Discussion}
Our discussion of the simulation results will cover 3 metrics: delay, throughput, and fairness.

\subsection*{Delay} Initially we kept $p$ within the realm of the assignment specifications,
i.e. $p \leq 0.04$. In Figure 1, notice that the delay for the protocols have deviated
significantly. In terms of this metric we can say that under the $T$ protocol, the average
amount of time a frame had to wait before being transmitted was the least. For the backoff
strategies we see protocols performed from better to worst in order $B$, $P$, $I$. At $p$=0.04
frame generation rate the Interval Based protocol performed the worst, with the average frame
waiting around 17,000 time slots before transmitting.


\subsection*{Throughput}

\subsection*{Fairness} In order to 

Explain results, contrast with expectations

%TODO: for R=5000, TBEB approaches like 0.9 something, so maybe we can extrapolate that with
%a sufficiently large trial, the throughput will approach 1?
%TODO - TDM delay should hypothetically spike when the per-station throughput 
%(which should approach 1/N at sufficiently high load) is lower than the generation probability...
%TODO -> probabalistic unfairness explanation - a couple 'lucky' stations get 
%through early, while others keep colliding - lucky stations keep transmitting
%, unlucky ones have large (1024) slot backoff, never get to transmit
-----
NB -
One thing to note could be limitations of our simulation - a global probability constant 
for frame generation assumes that all stations are providing the same level of load to 
the hub, which may not necessarily be true and could possibly have significant
repercussions on fairness, ie if most stations are pretty quiet, but one is SUPER active,
could it drown out the others in the various protocols in a way that is somehow unfair?
-----

\section*{Conclusions}

Rehash discussion?

(Under these applcations, use this protocol! Under others, use that!)

%    We have observed that a transmission scheme that splits frames into multiple Hamming's 
%    Single Bit Correction blocks can increase the scheme's resilience to higher bit rate 
%    errors with an effect proportional to the number of correction blocks per frame used. 
%    However, the correction comes at a price as throughput at lower than critical bit error
%    rates is proportionally reduced with more correction blocks. Increasing the number of 
%    correction blocks can increase the critical bit error rate where throughput collapses 
%    to zero by 
%    over an order of magnitude without sacrificing more than a 50\% decrease in throughput
%    at non-critical error levels. For situations with higher feedback delays, the improvements
%    offered by increased correction are
%    increased slightly, but for fully pipelined transmission schemes the effect is expected 
%    to be larger.

\end{document}
