\documentclass[twocolumn]{article}
\usepackage[letterpaper, left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{graphicx}
%\usepackage{estopdf}
\usepackage{verbatim}
\usepackage{listings}
\begin{document}

\lstset{
language=C,                             % Code langugage
basicstyle=\ttfamily,                   % Code font, Examples: \footnotesize, \ttfamily
numbers=left,                           % Line nums position
numberstyle=\tiny,                      % Line-numbers fonts
stepnumber=1,                           % Step between two line-numbers
numbersep=5pt,                          % How far are line-numbers from code
frame=none,                             % A frame around the code
tabsize=2,                              % Default tab size
captionpos=b,                           % Caption-position = bottom
breaklines=true,                        % Automatic line breaking?
breakatwhitespace=false,                % Automatic breaks only at whitespace?
showspaces=false,                       % Dont make spaces visible
showtabs=false,                         % Dont make tabls visible
columns=flexible                        % Column format
}

\title{CMPUT 313 Assignment 2}
\date{Tuesday, March 13}
\author{Stephen Jahns and Marek Kundera}

\maketitle

\section*{Introduction}

	Choosing an appropriate backoff strategy for the Slotted ALOHA MAC layer
	protocol depends on a series of factors. In this report, we have
	simulated the Probabilistic Backoff ($P$), Interval-Based Backoff ($I$),
	and Truncated Binary Exponential Backoff ($B$) strategies. In addition,
	we have simulated the Time Division Multiplexing ($T$) protocol for
	additional comparison. Our simulation was based on several assumptions
	found in the problem specification and on a terse description of each
	protocol:

$T$: a station $i$ only transmits at slot number $mN + i$, $m$ = 0, 1, 2, ...
$N$, where $m$ is the cycle number, and $N$ is the number of stations

$P$: a station will try to transmit immediately on generation, or retransmit
with $1/N$ probability at each subsequent slot

$I$: a station will try to transmit immediately on generation, or retransmit at
a slot 1 to $N$ slots later, chosen randomly

$B$: a station will try to transmit immediately on generation, or retransmit at
a slot 1 to 2 slots later, then 1 to 4 slots later, or eventually 1 to $2^i$
slots later, chosen randomly until the frame successfully transmits

	To set some groundwork, we will begin by outlining our expectations with
	a preliminary analysis. Next we will briefly explain the main
	functionality and design of our \verb|psim| simulator. Then we will reveal the
	simulation results with the help of some tables and graphs, paired with
	the parameters we used to generate the media. Finally, we will examine
	each protocol's performance by analyzing their average throughputs and
	the overall average per-frame slot time delays of the successfully
	transmitted frames. In addition, we will examine the fairness of each
	protocol by observing the number of undelivered frames under each
	protocol at the individual stations.

%	PSIM requires several parameters at the command line:
%
%\begin{center} Protocol N p R T seed1 seed2 ... seedT \end{center}
%
%The Protocol can taken on a value of '$T$', '$P$', '$I$', or '$B$', depending on
%what protocol is being simulated. The parameter $N$ represents the number of
%stations that will be transmitting under the protocol. $p$ represents the
%probability that a frame will be generated at each station. $R$ represents the
%number of slots that the experiment will run, and is therefore the time-measure
%for the experiment. And $T$ represents the number of trials the simulation will
%run, while the following $seed1...seedT$ inputs are used to reseed the
%randomization functions for each trial. For the purpose of this simulation, the
%values $N$=20, $R$=50,000, and $T$=5 will be fixed. In other words, we will
%simulate 5 trials where 20 stations transmit over a time period of 50,000 slots.
%The observations shown later are based on 5 trials that were seeded with values
%1, 2, 3, 4, 5, respectively.

\subsection*{Time Division Multiplexing} Here we expect that as the probability
of frame generation, $p$, increases, the average frame delay should increase. This is
because in any given cycle of $N$ slots, the probability of a frame being
generated at that slot increases. Therefore as $p$ increases, up to $N$ frames
might be generated in a cycle.  On the other hand, the mean throughput should
increase in direct proportion to $p$. As $p$ increases, it is more likely frames
will be available for transmission in a given cycle. In other words, it is more
likely a station will not waste its designated slot time. Furthermore, since
each station has a designated slot only it can transmit on, it is not possible
for collisions to occur between the stations.

\subsection*{Probabilistic Backoff} Notice that for a probability of successful
transmission of $1/N$, we need $N$ stations to each have a frame queued for
transmission, in order for one to \emph{likely} transmit. We can build on this
observation and hypothesize that at some $p$, every station will be generating
frames faster than it can transmit them. And therefore, the throughput will
level off in concert with the probability that \emph{exactly one} station
transmits, i.e. let event $ExactlyOneTx$ represent the case where exactly one
station is transmitting. Thus, when $N$=20 stations, $Prob(ExactlyOneTx)$ =
$C(20,1)\times(1/20)\times(19/20)^{19}$ = 0.377. For 20 stations, it is likely
then that when $p=0.377/20=0.019$, we can expect the throughput to begin
leveling off and for the average frame delay to start increasing. This is
because as $p$ increases, frames are more likely to generate, while the
throughput remains the same. And so, the queue can only get larger thus each
frame must wait longer before moving to the front of the queue for transmission.

\subsection*{Interval-Based Backoff} In a similar fashion to the probabilistic
backoff, as $p$ is increased, we predict that some critical point will be reached
where the rate of generation will be higher than the rate of transmission, and so the
queues at each station will grow, increasing the average frame delay. Additionally,
the throughput will level out as the probability of a collision stabilizes along with
the rate of successful transmission. Consider an analogy of $N$=20 buckets. At each time
slot, each station has $p$ chance of adding a 'ball to one bucket'. Therefore, in the
long run, the frames generated per slot is $N\times p$ while the rate of transmission
can be 1 at best, but realistically much lower (let's say $Z$). It is easy to see that
as $p$ increases, eventually the rate of generation will be greater than the rate of
transmission (or throughput), i.e. $N\times p \geq Z$. $Z$ can be said to be equal to
the probability that a bucket has exactly one ball. This isn't the same probability as
above, and it won't be calculated as it would involve higher level probabilistic math.
At this point however, the throughput will will level out and the average frame delay will increase
as $p$ increases.

\subsection*{Truncated Binary Exponential Backoff}


    %In this report, we analyze the effect of various degrees of error correction on data 
    %throughput versus a transmission scheme utilizing error detection alone. Intuitively,
    %one would expect error correction to be beneficial to throughput for the majority of cases,
    %for if the receiver can correct bit errors on reception, then entire frames would not 
    %need to be needlessly retransmitted. However, error correction comes at a price: extra bits
    %are required to be sent along with the frame when error correction schemes are applied.
    %For Hamming's Single Bit Error Correction (HSBC) scheme, a code of $m$ bits requires 
    %$k$ extra correction bits such that $2^k \geq m + k$. 

    %In order to scale up the ability of HSBC, which can only correct single bit errors, 
    %a frame to be transmitted can be split into $K$ blocks, where each block has HSBC applied
    %to it. Such a block could withstand up to $K$ bit errors while still being correctable 
    %at the receiver, if each of the bit errors was confined to a separate block within the 
    %frame. For lower values of $K$, the number of extra correction bits required is quite small.
    %The upper limit of this scheme is to split a frame of $F$ bits is split into $K = F$
    %correction blocks, and here the extra correction bits are not insignificant; there must be a 
    %correction bit
    %for every bit of real data in the frame. This immediately cuts the data throughput in
    %half.

    %To evaluate the utility of different error correction levels, we will experiment with 
    %how data throughput responds to varying bit error rates ($e$, where $e$ is the 
    %uniform probability that a transmitted bit is in error) for different levels of 
    %error correction ($K$, where $K$ is the number of single-bit error correctable blocks 
    %a frame is split into, and $K=0$ corresponds to a frames transmitted without an error 
    %correction scheme. 

\section*{Methods}

The \verb|psim| simulator was implemented in C++. It requires several parameters
at the command line:

\begin{center}\verb|psim Protocol N p R T seed1 seed2 ... seedT|\end{center}

 \verb|Protocol| can taken on a value of \verb|T|, \verb|P|, \verb|I|, or \verb|B|, depending on
what protocol is being simulated. The parameter \verb|N| represents the number of
stations that will be transmitting under the protocol. \verb|p| represents the
probability that a frame will be generated at each station. \verb|R| represents the
number of slots that the experiment will run, and is therefore the time-measure
for the experiment. And \verb|T| represents the number of trials the simulation will
run, while the following \verb|seed1...seedT| inputs are used to reseed the
randomization functions for each trial. 

For the purpose of this simulation, the
values \verb|N=20|, \verb|R=50000|, and \verb|T=5| will be fixed. In other words, we will
simulate 5 trials where 20 stations transmit over a time period of 50,000 slots.
The observations shown later are based on 5 trials that were seeded with values
1, 2, 3, 4, 5, respectively.

\verb|psim| functions by simulating \verb|T| independent trials of hub of
\verb|N| stations running for \verb|R| time slots, using the random number
generator seeds separately specified for each trial. At the beginning of each
timeslot, each station generates a new frame on its transmission queue with
probability \verb|p|. Then, the delay value in time slots is incremented for
each frame on each stations transmission queue.  Then, the simulator determines
which and how many stations will attempt transmission in that timeslot,
according to the MAC protocol specified in \verb|Protocol|. If there is only one
station attempting transmission, the transmission is deemed successful and the
frame is removed from that station's queue. If there are more than one
transmissions, a \verb|tx_collide(slot)| method is executed on each station that
partly implements the station's backoff protocol as specified in
\verb|Protocol|.

The simulator outputs the parameters (minus the seeds) on the first line. After
running all trials, it calculates and prints 95\% confidence intervals for the
overall average throughput in frames delivered per time slot, and delay in slots
for each frame successfully delivered, on lines 2 and 3 respectively. Delay was 
calculated from the time of frame generation to the time of successful delivery in slots,
in a matter that the minimum delay is 1 if the frame is generated in the same slot that it is
delivered in. Confidence
intervals were calculated using appropriate t-statistics for the number of
trials from a file labelled \verb|tvalues.dat|. Per-station statistics were output
on the remaining lines, where each line started with \verb|nN|, the id of the station,
followed by confidence intervals for throughput and delay per frame delivered, and finally
the ratio of undelivered frames to total frames generated by that station for each trial 
separately, all on the same line.

Experiments were automated using the BASH script \verb|make_plot.sh| 
to run the simulator for each protocol over ranges of \verb|p| values ranging
from 0.00 up to 0.04. The scripts parsed data from the output into appropriately
formatted data files that were sent to GNUPLOT for plotting.

    
   % The simulator program \verb|esim| was implemented in C++, and is called with:
   % \begin{lstlisting}
   % esim A K F e R T t1 t2 t3 ... tT
   % \end{lstlisting}
   % where \verb|A| is the feedback time in bit time units. \verb|K| is the number
   % of correction blocks used, \verb|F| is the size in bits of the frames to be transmitted,
   % \verb|e| is the bit error rate, \verb|R| is the maximum length in bit time units of
   % a single simulation trial, and \verb|T| is the number of trials to be simulated, with 
   % \verb|t1 t2 ... tT| being the seeds used for the simulator's random number generator
   % for each trial. After running, the simulator program outputs the means and 
   % 95\% confidence intervals for the average number of frames transmitted for each frame
   % successfully received (\verb|RATIO|), and for data throughput (\verb|TH|) as follows:

   % \begin{lstlisting}
   % esim A K F e R T t1 t2 t3 ... tT
   % A K F e R T t1 t2 t3 ... tT
   % RATIO (LOWER BOUND) (UPPER BOUND)
   % TH (LOWER BOUND) (UPPER BOUND)
   % \end{lstlisting}

   % The simulator simulates a stop-and-wait transmission scheme, where it simulates the 
   % transmission of the \verb|F|frame bits over \verb|F| bit time units, then simulates
   % a wait of \verb|A| bit time units for the feedback delay, after which it will either
   % start transmitting the next frame or retransmit the previous frame if there were 
   % uncorrectable errors. The transmission of each bit is simulated such that each bit
   % has a probability of \verb|e| of being in error. A frame is considered uncorrectable
   % if there are more than \verb|K| simulated errors within a correction block, or for
   % \verb|K = 0|, if there are any errors within the frame. To calculate the confidence
   % intervals, the simulator picks an appropriate t-statistic from a file labeled 
   % \verb|tvalues.dat| for the degrees of freedom equal to \verb|T - 1|, so the file must 
   % be present when running the simulator to get accurate confidence intervals (otherwise
   % a blanket t-statistic is assumed).

   % All simulations were run with frame size of 8000 bits, \verb|T = 5| trials with
   % different integer seeds used for each trial (1 - 5).

   % A BASH script, \verb|make_plot.sh| was written to automate the execution of multiple 
   % simulations over a range of values of \verb|K| and \verb|e|, collect the simulation 
   % outputs, and format and pipe the data to GNUPLOT for plotting.


\section*{Results}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/delay_big.eps}
    \caption{\footnotesize  Average delay per frame under each protocol for
    $p$:(0,0.04; @0.005 increments). Used to illustrate what happens as $p$
    nears 0.04.} \label{fig:delay_big}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/throughput_big.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0,0.04; @0.005 increments). Used to illustrate what happens as $p$
    nears 0.04.} \label{fig:throughput_big}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/small_delay.eps}
    \caption{\footnotesize Average delay per frame under each protocol for
    $p$:(0,0.015; @0.001 increments). Used to illustrate what happens as $p$
    nears 0.} \label{fig:delay_small}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/small_throughput.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0,0.015; @0.001 increments). Used to illustrate what happens as $p$
    nears 0.} \label{fig:throughput_small}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/ib_diverge_delay.eps}
    \caption{\footnotesize Average delay per frame under each protocol for
    $p$:(0,0.02; @0.001 increments). Used to illustrate where protocols begin to
    diverge significantly. Especially, protocol $I$ at $p$=0.015.}
    \label{fig:delay_ib}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/ib_diverge_throughput.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0,0.02; @0.001 increments). Used to illustrate where protocols
    begin to diverge significantly. Especially, protocol $I$ at $p$=0.016.}
    \label{fig:throughput_ib}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/tpbi_delay.eps}
    \caption{\footnotesize Average delay per frame under each protocol for
    $p$:(0.01,0.021; @0.001 increments). Used to illustrate the points where the
    protocols intersect.} \label{fig:delay_diverging}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/tpbi_throughput.eps}
    \caption{\footnotesize Mean throughput of all stations under each protocol
    for $p$:(0.01,0.021; @0.001 increments). Used to illustrate the points where
    the throughput for protocols $I$ and $P$ begins to level off.}
    \label{fig:throughput_diverging}
\end{figure}


For ranges of frame generation probabilities per station per slot ranging
from 0.0 to 0.04, plots of average delay in slots per frame successfully delivered and
of throughput in number of frames per timeslot were obtained. 

In Figure~\ref{fig:delay_big}, we see that over larger values of $p$ ranging up to
0.04, there is a clear separation in delay levels for each protocol. Interval backoff
produces the largest delays, followed by probabilistic backoff. Truncated binary exponential
backoff produces the least delays of the Slotted ALOHA MAC protocols. Time division multiplexing,
however, provides delivery delays at $p=0.04$ that are a tiny fraction of the delays of the 
ALOHA protocols. Similar results exist for throughput at higher loads ($p$ approaching 0.04) as 
seen in Figure~\ref{fig:throughput_big}. TBEB provides the highest throughput at high load,
followed by IB and PB. TDM provides a higher throughput at high load than the ALOHA protocols,
but by a much smaller margin (~10\% higher than TBEB) than exhibited by the difference in
delays.

At smaller loads (approx. $p<0.013$), the frame delivery delays for TDM become
larger than that of the ALOHA protocols (Figure~\ref{fig:delay_small}). The relative delays 
between the different ALOHA protocols also changes. For $p<0.012$, TBEB has the smallest delay,
but the delay increases strongly above that value. Interval backoff has the smallest delays
for 
$p \in (0.012, 0.016)$, after which the delay for IB jumps up sharply (Figure~\ref{fig:delay_ib}).
For $p > 0.016$, TDM has less delay than any of the ALOHA protocols, and PB has the smallest 
delay of the ALOHA protocols for $p \in (0.016, 0.02)$, after which the delay jumps to above
that of TBEB (Figure~\ref{fig:delay_diverging}). TBEB has the least delay of the ALOHA protocols
for $p > 0.02$.

All protocols produce very similar throughputs at low load for $p \in (0, 0.016)$
(see Figures ~\ref{fig:throughput_small} and ~\ref{fig:throughput_ib}), where
all throughputs appear to increase linearly with frame generation probability. 
Above $p=0.016$, IB throughput drops fairly quickly by about 20\% and flattens to a throughput
of about 25\% for all higher loads. Above $p=0.02$, PB throughput drops a little and flattens
to about 40\% for all higher loads. 

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/fullrange_delay5000.eps}
    \caption{Average delay per frame delivered on hub for full range of per
    slot, per station frame generation probability, tested for each MAC
    protocol  $R=5000$ slots, $T = 5$ trials }
    \label{fig:fullrange_delay}

    \begin{tabular}{l|c|c|c|c|c}
B 20 0.040000 1000 5 1 2 3 4 5
0.406200 0.388525 0.423875
117.545544 91.008666 144.082422
n1 0.900000 0.547619 0.860000 0.968750 0.787234
n2 1.000000 0.468085 1.000000 0.220339 0.615385
n3 0.840909 0.394737 0.000000 1.000000 1.000000
n4 0.195652 0.000000 0.027778 0.411765 0.000000
n5 0.545455 0.023810 0.407407 0.000000 1.000000
n6 0.860465 0.634146 0.037037 0.954545 0.687500
n7 1.000000 0.731707 0.000000 0.125000 0.000000
n8 0.097561 1.000000 0.585366 0.000000 1.000000
n9 0.163265 0.511628 0.000000 0.925000 1.000000
n10 0.159091 1.000000 0.692308 0.488372 0.024390
n11 0.230769 0.000000 0.770833 1.000000 0.142857
n12 0.000000 0.961538 0.974359 0.386364 0.025641
n13 0.955556 0.025000 0.545455 0.060606 0.957447
n14 0.000000 0.026316 0.000000 0.846154 0.795455
n15 0.800000 0.954545 0.057143 0.342857 0.545455
n16 0.000000 1.000000 1.000000 0.815789 0.111111
n17 0.918919 0.000000 0.534884 1.000000 0.068182
n18 0.189189 0.725000 0.052632 0.000000 0.037736
n19 0.000000 0.666667 0.962963 0.119048 1.000000
n20 0.860465 0.276596 0.903226 0.481481 0.173913
\end{figure}

For the range of $p$ values that could be tested using \verb|R=50000| (higher
$p$ values resulted in at least polynomially higher simulation run times as the frame queues
became heavier loaded), we did not see a point where TBEB throughput levels off. Running
the simulator under the same conditions as before but with \verb|R=1000| and \verb|p| ranging
from 0 to 1, TBEB throughput appears to increase steadily until about 78\% at about $p = 0.5$,
and the same plot for \verb|R=5000| shows TBEB throughput leveling off at about 93\% 
(Figure~\ref{fig:fullrange_delay}). At \verb|R=5000|, IB and PB delays appear to level off at the
same values as for \verb|R=50000|.

In Figure~\ref{fig:fullrange_delay}, we also see that with sufficiently high load, TBEB yields
a lower average delay than T



\begin{figure}
    \centering \includegraphics[width=8cm]{plots/fullrange_delay5000.eps}
    \caption{Average delay per frame delivered on hub for full range of per
    slot, per station frame generation probability, tested for each MAC
    protocol  $R=5000$ slots, $T = 5$ trials }
    \label{fig:fullrange_delay}
\end{figure}

\begin{figure}
    \centering \includegraphics[width=8cm]{plots/fullrange_throughput5000.eps}
    \caption{Average throughput on hub for full range of per
    slot, per station frame generation probability, tested for each MAC
    protocol  $R=5000$ slots, $T = 5$ trials } 
    \label{fig:fullrange_throughput}
\end{figure}


TODO figure
TODO!!! Running with R=1000 shows TDM delay jumping after t=0.1 to above that of TBEB...

TODO - TDM delay should hypothetically spike when the per-station throughput 
(which should approach 1/N at sufficiently high load) is lower than the generation probability...

TODO Large load TBEB delay looks to be about half that of all the others... Also error increases
with higher load -- somehow related to unfairness?

TODO make distinction between Average Throughput used in most plots vs average per-station 
throughput

TODO - unfairness -> look at ratio of undelivered/total generated frames at very high load
                     for TBEB -> looks like some stations get to deliver most frames while others
                     might not get any through on some trials....

                     -> probabalistic unfairness explanation - a couple 'lucky' stations get 
                     through early, while others keep colliding - lucky stations keep transmitting
                     , unlucky ones have large (1024) slot backoff, never get to transmit

     -> Plot/Figure -> Maybe just a table of undelivered/genrated ratios for station and trial
                        -> point out that on some trials, some stations have ~1, others are as 
                        low as 0.3


Describe results TODO: tables of undelivered/generated

%    In Figure~\ref{fig:kthroughput}, a plot was obtained that shows the relationship between 
%    throughput and bit error rate for different numbers of error correction blocks. $K=0$ 
%    corresponds to a transmission scheme with only error detection and no error correction.
%    For very low bit error rates, $K=0$ provides the highest simulated throughput. As bit 
%    error rate increases, the best throughput is overtaken by error correction schemes 
%    corresponding to progressively higher numbers of $K$. The highest possible value for 
%    $K$ with a frame size of 8000 bits, $K=4000$, is shown to be able to withstand the highest
%    bit error rate before collapsing to 0, but with the drawback of a drastically reduced upper
%    bound of below 50\% throughput at lower bit error rates. The relationship between
%    throughput and bit error rate for a constant $K$ appears to resemble a hyperbolic tangent.
%
%    Looking at Figure~\ref{fig:kframes}, the bit rates at which each correction scheme 
%    collapses is very visible. $K=0$ collapses in the middle range of $(0.0001, 0.001)$, and
%    $K=4000$ collapses at around 0.01.
%
%    To observe how changes to the feedback time effect the relative performance of different
%    $K$-values, in Figure~\ref{fig:a} throughput versus bit error rate was plotted for a 
%    small range of $K$ for 3 different values of $A$, where $A$ is the feedback time in bit
%    time units (Figure~\ref{fig:a10000}). Increasing A causes strong, even reductions in the 
%    throughput for all $K$-values, as well as affecting the relative performance of different 
%    $K$-values at certain ranges of bit error rate $e$. For $A=100$, $K=0$ outperforms $K=1$ 
%    for $e < 10^{-7}$,
%    and $K=0$ outperforms $K=10$ for around $e < 10^{-6}$. Increasing $A$ reduces the range where
%    correctionless schemes can outperform schemes with correction, as for $A=100000$, $K=0$ 
%    outperforms $K=1$ and $K=10$ for values of $e$ below around $10^{-7}$, $10^{-8}$ 
%    respectively.
%
%\begin{figure}
%    \centering
%    \includegraphics[width=8cm]{plots/fig1.eps}
%    \caption{ Simulated throughputs for varying bit error rates and numbers of correction
%    blocks. Error bars denote 95\% confidence intervals. Fixed parameters used were 
%    $A = 100$, $R = 10^6$, $T=5$. X-axis is log scale. }
%    \label{fig:kthroughput}
%\end{figure}
%
%\begin{figure}
%    \centering
%    \includegraphics[width=8cm]{plots/fig2.eps}
%    \caption{ Simulated average frames transmitted for each correct frame received, for
%    various bit error rates and numbers of correction blocks. Error bars denote 
%    95\% confidence intervals. Fixed parameters used were 
%    $A = 100$, $R = 10^6$, $T=5$. }
%    \label{fig:kframes}
%\end{figure}
%
%\begin{figure}
%    \centering
%    \includegraphics[width=8cm]{plots/fig5.eps}
%    \caption{ Simulated throughput response at feedback delay $A=10000$ bit time units. 
%        All other parameters are the same as those used in Figure~\ref{fig:kthroughput}.
%    }
%    \label{fig:a10000}
%\end{figure}
%
%\begin{figure}
%    \centering
%    \includegraphics[width=8cm]{plots/fig4_100.eps}
%    \includegraphics[width=8cm]{plots/fig4_10000.eps}
%    \includegraphics[width=8cm]{plots/fig4_100000.eps}
%    \caption{ Increasing values of $A$. The top plot is for $A=100$, with $R=10^7$. The middle
%    plot is for $A=10000$, with $R=10^7$. The bottom plot is for $A=100000$, with $R=10^8$.
%    $T=5$ in all cases. X-axis is log scale. } 
%    \label{fig:a}
%\end{figure}


\section*{Discussion}

Explain results, contrast with expectations

%TODO: for R=5000, TBEB approaches like 0.9 something, so maybe we can extrapolate that with
%a sufficiently large trial, the throughput will approach 1?
-----
NB -
One thing to note could be limitations of our simulation - a global probability constant 
for frame generation assumes that all stations are providing the same level of load to 
the hub, which may not necessarily be true and could possibly have significant
repercussions on fairness, ie if most stations are pretty quiet, but one is SUPER active,
could it drown out the others in the various protocols in a way that is somehow unfair?
-----

%    When looking to maximize throughput, the most appropriate value for $K$, where $K$ 
%    is the number of error correction blocks,
%    is a function of the bit error rate $e$. For sufficiently low values of $e$, $K=0$ 
%    performs the best because the error rate is not high enough for the 
%    performance boosts error correction to overcome the extra overhead of sending along 
%    correction bits.
%
%    As the bit error rate increases, $K=0$ begins to suffer, as any time a single bit 
%    error is encountered, the entire frame must be retransmitted. For $K$-values greater
%    than 0, frames can withstand up to $K$ single bit errors before requiring retransmission. 
%    However, these cannot be any $K$ random bit errors in the frame, otherwise for 
%    $K=4000$ should be able to withstand $e$ up to 0.5. For $K$ single bit errors to be 
%    corrected, the $K$ errors must be distributed such that each error is in a separate 
%    correction block, which is a lower probability event than a more random scattering such that
%    a correction block contains more than one bit error, where the frame must be dropped and
%    retransmitted.
%
%    Increasing the number of correction blocks arbitrarily to maximize resilience against 
%    error is not the best approach. Using the maximum number of correction blocks possible
%    may maintain throughput without collapsing for the highest bit error rates, but for 
%    any bit error rate less than that, a slightly smaller number of correction blocks will 
%    likely give a significantly higher throughput due to the hyperbolic tangent shape of the
%    throughput curve. Also with the maximum number of correction blocks, even with an error
%    probability of zero, the throughput will be capped at 50\% since have the bits in the 
%    frame are overhead for error correction.
%
%    Higher feedback delay values were also investigated. It could be expected that the cost
%    of retransmitting a frame grows higher as feedback delays increase, and thus would
%    lend to the idea that with higher feedback delays, the relative performance of 
%    schemes utilizing receiver-size error correction would improve with respect to uncorrected
%    schemes. This was observed to be the case to some extend as seen in Figure~\ref{fig:a}, 
%    where $K=0$ remains the top performer for higher error rates at lower delays than at higher
%    delays. This effect would likely be more pronounced if the transmission scheme were a 
%    fully pipelined, sliding window scheme rather than a stop and wait scheme. Since this 
%    scheme is stop and wait, when the delay is much longer than the transmission time, 
%    throughput is decreased dramatically as the sender must wait for receiver to acknowledge
%    the sender's frames. With a fully pipelined scheme, the connection could be utilized with
%    near 100\% throughput if the error correction is able to keep up, while a correctionless
%    scheme could collapse at the same error rate with no error tolerance and such large feedback
%    delays.
%
%    In general, the simulated results from these experiments likely overestimate the throughput
%    generated by the correction schemes, as real world bit errors often come in bursts rather
%    than uniformly distributed. This would result in a higher likelihood of correction blocks
%    that contain multiple bit errors, and thus an increased rate of dropped frames that 
%    must be retransmitted.

\section*{Conclusions}

Rehash discussion?

(Under these applcations, use this protocol! Under others, use that!)

%    We have observed that a transmission scheme that splits frames into multiple Hamming's 
%    Single Bit Correction blocks can increase the scheme's resilience to higher bit rate 
%    errors with an effect proportional to the number of correction blocks per frame used. 
%    However, the correction comes at a price as throughput at lower than critical bit error
%    rates is proportionally reduced with more correction blocks. Increasing the number of 
%    correction blocks can increase the critical bit error rate where throughput collapses 
%    to zero by 
%    over an order of magnitude without sacrificing more than a 50\% decrease in throughput
%    at non-critical error levels. For situations with higher feedback delays, the improvements
%    offered by increased correction are
%    increased slightly, but for fully pipelined transmission schemes the effect is expected 
%    to be larger.

\end{document}
